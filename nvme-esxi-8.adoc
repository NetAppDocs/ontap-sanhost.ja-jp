---
sidebar: sidebar 
permalink: nvme-esxi-8.html 
keywords: nvme, esxi, ontap, nvme/fc, hypervisor 
summary: ESXi 8.xおよびONTAP を実行するイニシエータホストでは、NVMe over Fabrics（NVMe-oF）をターゲットとして設定できます。 
---
= ONTAP を搭載したESXi 8.x向けのNVMe-oFホスト構成
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
ESXi 8.xおよびONTAP を実行するイニシエータホストでは、NVMe over Fabrics（NVMe-oF）をターゲットとして設定できます。



== サポート性

* 以降では、新しく作成するすべてのONTAP 9ネームスペースに対してスペースの割り当てがデフォルトで有効になります。
* ONTAP 9.9.1 P3以降では、ESXi 8以降でNVMe/FCプロトコルがサポートされます。
* ONTAP 9.10.1以降では、ONTAP でNVMe/TCPプロトコルがサポートされます。




== の機能

* ESXiイニシエータホストでは、NVMe/FCトラフィックとFCPトラフィックの両方を、同じアダプタポート経由で実行できます。を参照してください link:https://hwu.netapp.com/Home/Index["Hardware Universe"^] サポートされる FC アダプタおよびコントローラの一覧を表示するには、を参照してください。を参照してください link:https://mysupport.netapp.com/matrix/["NetApp Interoperability Matrix Tool で確認できます"^] サポートされる構成およびバージョンの最新のリストについては、を参照してください。
* ESXi 8.0以降のリリースでは、NVMeデバイスのデフォルトのプラグインはHPP（ハイパフォーマンスプラグイン）です。




== 既知の制限

* RDMマッピングはサポートされていません。




== NVMe/FC を有効にします

NVMe/FCはvSphereリリースでデフォルトで有効になります。

.ホストNQNを確認
ESXiホストのNQN文字列を確認し、ONTAP アレイの対応するサブシステムのホストのNQN文字列と一致することを確認する必要があります。

[listing]
----
# esxcli nvme info get
----
出力例：

[listing]
----
Host NQN: nqn.2014-08.org.nvmexpress:uuid:62a19711-ba8c-475d-c954-0000c9f1a436
----
[listing]
----
# vserver nvme subsystem host show -vserver nvme_fc
----
出力例：

[listing]
----
Vserver Subsystem Host NQN
------- --------- ----------------------------------------------------------
nvme_fc nvme_ss  nqn.2014-08.org.nvmexpress:uuid:62a19711-ba8c-475d-c954-0000c9f1a436
----
ホストのNQN文字列が一致しない場合は、を使用してください `vserver nvme subsystem host add` コマンドを実行して、対応するONTAP NVMeサブシステムで正しいホストNQN文字列を更新します。



== Broadcom/EmulexおよびMarvell/Qlogicを設定します

。 `lpfc` ドライバおよび `qlnativefc` vSphere 8.xのドライバでは、NVMe/FC機能がデフォルトで有効になっています。

設定がドライバまたはファームウェアでサポートされているかどうかを確認するには、を参照してくださいlink:https://mysupport.netapp.com/matrix/["Interoperability Matrix Tool"^]。



== NVMe/FC を検証

NVMe/FCの検証には、次の手順 を使用できます。

.手順
. NVMe/FCアダプタがESXiホストに表示されていることを確認します。
+
[listing]
----
# esxcli nvme adapter list
----
+
出力例：

+
[listing]
----

Adapter  Adapter Qualified Name           Transport Type  Driver      Associated Devices
-------  -------------------------------  --------------  ----------  ------------------
vmhba64  aqn:lpfc:100000109b579f11        FC              lpfc
vmhba65  aqn:lpfc:100000109b579f12        FC              lpfc
vmhba66  aqn:qlnativefc:2100f4e9d456e286  FC              qlnativefc
vmhba67  aqn:qlnativefc:2100f4e9d456e287  FC              qlnativefc
----
. NVMe/FCネームスペースが正しく作成されたことを確認します。
+
次の例の UUID は、 NVMe / FC ネームスペースデバイスを表しています。

+
[listing, subs="+quotes"]
----
# esxcfg-mpath -b
uuid.116cb7ed9e574a0faf35ac2ec115969d : NVMe Fibre Channel Disk (*uuid.116cb7ed9e574a0faf35ac2ec115969d*)
   vmhba64:C0:T0:L5 LUN:5 state:active fc Adapter: WWNN: 20:00:00:24:ff:7f:4a:50 WWPN: 21:00:00:24:ff:7f:4a:50  Target: WWNN: 20:04:d0:39:ea:3a:b2:1f WWPN: 20:05:d0:39:ea:3a:b2:1f
   vmhba64:C0:T1:L5 LUN:5 state:active fc Adapter: WWNN: 20:00:00:24:ff:7f:4a:50 WWPN: 21:00:00:24:ff:7f:4a:50  Target: WWNN: 20:04:d0:39:ea:3a:b2:1f WWPN: 20:07:d0:39:ea:3a:b2:1f
   vmhba65:C0:T1:L5 LUN:5 state:active fc Adapter: WWNN: 20:00:00:24:ff:7f:4a:51 WWPN: 21:00:00:24:ff:7f:4a:51  Target: WWNN: 20:04:d0:39:ea:3a:b2:1f WWPN: 20:08:d0:39:ea:3a:b2:1f
   vmhba65:C0:T0:L5 LUN:5 state:active fc Adapter: WWNN: 20:00:00:24:ff:7f:4a:51 WWPN: 21:00:00:24:ff:7f:4a:51  Target: WWNN: 20:04:d0:39:ea:3a:b2:1f WWPN: 20:06:d0:39:ea:3a:b2:1f
----
+
[NOTE]
====
ONTAP 9.7では、NVMe/FCネームスペースのデフォルトのブロックサイズは4Kです。このデフォルトサイズは ESXi に対応していません。そのため、ESXiのネームスペースを作成する場合は、ネームスペースのブロックサイズを* 512B *に設定する必要があります。これは、を使用して実行できます `vserver nvme namespace create` コマンドを実行します

例：

vserver nvme namespace create -vserver vs_1 -path /vol/namespace1-size 100g -ostype vmware-block-size 512B

を参照してください link:https://docs.netapp.com/us-en/ontap/concepts/manual-pages.html["ONTAP 9 コマンドのマニュアルページ"^] を参照してください。

====
. それぞれの NVMe/FC ネームスペースデバイスの個々の ANA パスのステータスを確認します。
+
[listing, subs="+quotes"]
----
# esxcli storage hpp path list -d uuid.df960bebb5a74a3eaaa1ae55e6b3411d

fc.20000024ff7f4a50:21000024ff7f4a50-fc.2004d039ea3ab21f:2005d039ea3ab21f-uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Runtime Name: vmhba64:C0:T0:L3
   Device: uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Device Display Name: NVMe Fibre Channel Disk (uuid.df960bebb5a74a3eaaa1ae55e6b3411d)
   Path State: active unoptimized
   Path Config: {ANA_GRP_id=4,*ANA_GRP_state=ANO*,health=UP}

fc.20000024ff7f4a51:21000024ff7f4a51-fc.2004d039ea3ab21f:2008d039ea3ab21f-uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Runtime Name: vmhba65:C0:T1:L3
   Device: uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Device Display Name: NVMe Fibre Channel Disk (uuid.df960bebb5a74a3eaaa1ae55e6b3411d)
   Path State: active
   Path Config: {ANA_GRP_id=4,*ANA_GRP_state=AO*,health=UP}

fc.20000024ff7f4a51:21000024ff7f4a51-fc.2004d039ea3ab21f:2006d039ea3ab21f-uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Runtime Name: vmhba65:C0:T0:L3
   Device: uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Device Display Name: NVMe Fibre Channel Disk (uuid.df960bebb5a74a3eaaa1ae55e6b3411d)
   Path State: active unoptimized
   Path Config: {ANA_GRP_id=4,*ANA_GRP_state=ANO*,health=UP}

fc.20000024ff7f4a50:21000024ff7f4a50-fc.2004d039ea3ab21f:2007d039ea3ab21f-uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Runtime Name: vmhba64:C0:T1:L3
   Device: uuid.df960bebb5a74a3eaaa1ae55e6b3411d
   Device Display Name: NVMe Fibre Channel Disk (uuid.df960bebb5a74a3eaaa1ae55e6b3411d)
   Path State: active
   Path Config: {ANA_GRP_id=4,*ANA_GRP_state=AO*,health=UP}

----




== NVMe/FC を設定

ESXi 8.xでは、必要なNVMe/TCPモジュールがデフォルトでロードされます。ネットワークとNVMe/TCPアダプタの設定については、VMware vSphereのドキュメントを参照してください。



== NVMe/FCを検証

NVMe/TCPの検証には、次の手順 を使用できます。

.手順
. NVMe/TCPアダプタのステータスを確認します。
+
[listing]
----
esxcli nvme adapter list
----
+
出力例：

+
[listing]
----
Adapter  Adapter Qualified Name           Transport Type  Driver   Associated Devices
-------  -------------------------------  --------------  -------  ------------------
vmhba65  aqn:nvmetcp:ec-2a-72-0f-e2-30-T  TCP             nvmetcp  vmnic0
vmhba66  aqn:nvmetcp:34-80-0d-30-d1-a0-T  TCP             nvmetcp  vmnic2
vmhba67  aqn:nvmetcp:34-80-0d-30-d1-a1-T  TCP             nvmetcp  vmnic3
----
. NVMe/TCP接続のリストを取得します。
+
[listing]
----
esxcli nvme controller list
----
+
出力例：

+
[listing]
----
Name                                                  Controller Number  Adapter  Transport Type  Is Online  Is VVOL
---------------------------------------------------------------------------------------------------------  -----------------  -------
nqn.2014-08.org.nvmexpress.discovery#vmhba64#192.168.100.166:8009  256  vmhba64  TCP                  true    false
nqn.1992-08.com.netapp:sn.89bb1a28a89a11ed8a88d039ea263f93:subsystem.nvme_ss#vmhba64#192.168.100.165:4420 258  vmhba64  TCP  true    false
nqn.1992-08.com.netapp:sn.89bb1a28a89a11ed8a88d039ea263f93:subsystem.nvme_ss#vmhba64#192.168.100.168:4420 259  vmhba64  TCP  true    false
nqn.1992-08.com.netapp:sn.89bb1a28a89a11ed8a88d039ea263f93:subsystem.nvme_ss#vmhba64#192.168.100.166:4420 260  vmhba64  TCP  true    false
nqn.2014-08.org.nvmexpress.discovery#vmhba64#192.168.100.165:8009  261  vmhba64  TCP                  true    false
nqn.2014-08.org.nvmexpress.discovery#vmhba65#192.168.100.155:8009  262  vmhba65  TCP                  true    false
nqn.1992-08.com.netapp:sn.89bb1a28a89a11ed8a88d039ea263f93:subsystem.nvme_ss#vmhba64#192.168.100.167:4420 264  vmhba64  TCP  true    false

----
. NVMeネームスペースへのパスの数のリストを取得します。
+
[listing, subs="+quotes"]
----
esxcli storage hpp path list -d *uuid.f4f14337c3ad4a639edf0e21de8b88bf*
----
+
出力例：

+
[listing, subs="+quotes"]
----
tcp.vmnic2:34:80:0d:30:ca:e0-tcp.192.168.100.165:4420-uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Runtime Name: vmhba64:C0:T0:L5
   Device: uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Device Display Name: NVMe TCP Disk (uuid.f4f14337c3ad4a639edf0e21de8b88bf)
   Path State: active
   Path Config: {ANA_GRP_id=6,*ANA_GRP_state=AO*,health=UP}

tcp.vmnic2:34:80:0d:30:ca:e0-tcp.192.168.100.168:4420-uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Runtime Name: vmhba64:C0:T3:L5
   Device: uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Device Display Name: NVMe TCP Disk (uuid.f4f14337c3ad4a639edf0e21de8b88bf)
   Path State: active unoptimized
   Path Config: {ANA_GRP_id=6,*ANA_GRP_state=ANO*,health=UP}

tcp.vmnic2:34:80:0d:30:ca:e0-tcp.192.168.100.166:4420-uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Runtime Name: vmhba64:C0:T2:L5
   Device: uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Device Display Name: NVMe TCP Disk (uuid.f4f14337c3ad4a639edf0e21de8b88bf)
   Path State: active unoptimized
   Path Config: {ANA_GRP_id=6,*ANA_GRP_state=ANO*,health=UP}

tcp.vmnic2:34:80:0d:30:ca:e0-tcp.192.168.100.167:4420-uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Runtime Name: vmhba64:C0:T1:L5
   Device: uuid.f4f14337c3ad4a639edf0e21de8b88bf
   Device Display Name: NVMe TCP Disk (uuid.f4f14337c3ad4a639edf0e21de8b88bf)
   Path State: active
   Path Config: {ANA_GRP_id=6,*ANA_GRP_state=AO*,health=UP}
----




== NVMeの割り当て解除

nvme deallocateコマンドは、ONTAP 9.16.1以降のESXi 8.0u2以降でサポートされます。

NVMeネームスペースでは、割り当て解除のサポートは常に有効になります。また、割り当てを解除すると、ゲストOSはVMFSデータストアで「マッピング解除」（「トリム」と呼ばれることもあります）処理を実行できます。割り当て解除処理を使用すると、有効なデータがなくなったために不要になったデータブロックをホストが識別できます。その後、ストレージシステムはこれらのデータブロックを削除して、スペースを他の場所で消費できるようにします。

.手順
. ESXiホストで、DSMの割り当て解除とTP4040のサポートの設定を確認します。
+
`esxcfg-advcfg -g /Scsi/NVmeUseDsmTp4040`

+
想定される値は0です。

. TP4040サポートによるDSM割り当て解除の設定を有効にします。
+
`esxcfg-advcfg -s 1 /Scsi/NvmeUseDsmTp4040`

. TP4040サポートによるDSMの割り当て解除の設定が有効になっていることを確認します。
+
`esxcfg-advcfg -g /Scsi/NVmeUseDsmTp4040`

+
想定される値は1です。



VMware vSphereでのNVMeの割り当て解除の詳細については、を参照してください。 https://techdocs.broadcom.com/us/en/vmware-cis/vsphere/vsphere/8-0/vsphere-storage-8-0/storage-provisioning-and-space-reclamation-in-vsphere/storage-space-reclamation-in-vsphere.html["vSphereでのストレージスペースの再生"^]



== 既知の問題

ONTAPを使用したESXi 8.xのNVMe-oFホスト構成には、次の既知の問題があります。

[cols="10,30,30"]
|===
| NetApp バグ ID | タイトル | 説明 


| link:https://mysupport.netapp.com/site/bugs-online/product/ONTAP/BURT/1420654["1420654"^] | ONTAP バージョン9.9.1でNVMe/FCプロトコルが使用されている場合、ONTAP ノードが動作しなくなります | ONTAP 9.9.1では、nvmeの「abort」コマンドがサポートされるようになりました。パートナーコマンドを待機しているnvme fusedコマンドを中止する「abort」コマンドをONTAP が受信すると、ONTAP ノードが停止します。問題 は、nvme fusedコマンド（ESXなど）とFibre Channel（FC）転送を使用するホストでのみ認識されます。 


| 1543660 | vNVMeアダプタを使用するLinux VMで[All Paths Down（APD；すべてのパスが停止）]ウィンドウが長くなると、I/Oエラーが発生します  a| 
vSphere 8.x以降を実行していて、仮想NVMe（vNVME）アダプタを使用しているLinux VMでは、vNVMeの再試行処理がデフォルトで無効になっているため、I/Oエラーが発生します。オールパスダウン（APD）時や大量のI/O負荷時に古いカーネルを実行しているLinux VMでの停止を回避するために、VMwareでは、vNVMeの再試行処理を無効にするための調整可能な「VSCSIDisableNvmeRetry」を導入しました。

|===
.関連情報
link:https://docs.netapp.com/us-en/ontap-apps-dbs/vmware/vmware-vsphere-overview.html["ONTAP を使用した VMware vSphere"^] link:https://kb.vmware.com/s/article/2031038["NetApp MetroCluster での VMware vSphere 5.x 、 6.x 、および 7.x のサポート（ 2031038 ）"^] link:https://kb.vmware.com/s/article/83370["NetApp SnapMirror Active SyncによるVMware vSphere 6.xおよび7.xのサポート"^]
