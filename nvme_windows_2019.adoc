---
sidebar: sidebar 
permalink: nvme_windows_2019.html 
keywords: nvme, windows, enterprise 
summary: Windows Server 2019を実行しているホストでONTAP LUNを使用するためにNVMe over Fibre Channel（NVMe/FC）を設定できます。 
---
= ONTAP 搭載の Windows Server 2019 向け NVMe/FC ホスト構成
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Windows Server 2019を実行しているホストでは、ONTAP LUNで処理するためにNVMe over Fibre Channel（NVMe/FC）を設定できます。

.このタスクについて
Windows 2019のNVMe/FCホスト構成では、次のサポートを使用できます。設定プロセスを開始する前に、既知の制限事項も確認しておく必要があります。


NOTE: この手順で説明する構成設定を使用して、およびに接続されているクラウドクライアントを構成できlink:https://docs.netapp.com/us-en/cloud-manager-cloud-volumes-ontap/index.html["Cloud Volumes ONTAP"^]link:https://docs.netapp.com/us-en/cloud-manager-fsx-ontap/index.html["ONTAP 対応の Amazon FSX"^]ます。

* 利用可能なサポート：
+
ONTAP 9.7以降では、Windows Server 2019でNVMe/FCがサポートされます。

+
サポートされるFCアダプタとコントローラの一覧については、を参照してくださいlink:https://hwu.netapp.com/Home/Index["Hardware Universe"^]。サポートされる構成とバージョンの最新のリストについては、を参照してくださいlink:https://mysupport.netapp.com/matrix/["Interoperability Matrix Tool"^]。

* 既知の制限事項：
+
WindowsフェイルオーバークラスタはNVMe/FCではサポートされていません。これは、ONTAPでは現在NVMe/FCによる永続的予約がサポートされていないためです。

+

NOTE: Broadcomには、Windows NVMe/FC用の外部ドライバが付属しています。これは、真のNVMe/FCドライバではありません。トランスレーショナルオーバーヘッドがパフォーマンスに影響するとは限りませんが、NVMe/FCのパフォーマンス上のメリットが失われます。そのため、WindowsサーバではNVMe/FCとFCPのパフォーマンスが同じですが、Linuxなどの他のオペレーティングシステムではNVMe/FCのパフォーマンスがFCPよりも大幅に優れています。





== NVMe/FC を有効にします

WindowsイニシエータホストでFC / NVMeを有効にします。

.手順
. WindowsホストにEmulex HBA Managerユーティリティをインストールします。
. 各 HBA イニシエータポートで、次の HBA ドライバパラメータを設定します。
+
** EnableNVMe = 1
** NVMEMode = 0


. ホストをリブートします。




== Broadcom FCアダプタの設定

Broadcomイニシエータは、同じ32G FCアダプタポートでNVMe/FCとFCPの両方のトラフィックに対応できます。FCPおよびFC / NVMeの場合は、Microsft Device-Specific Module（DSM；デバイス固有モジュール）をMicrosoft Multipath I/O（MPIO；マルチパスI/O）オプションとして使用する必要があります。

は、 `+hostnqn+`Windows環境でFC / NVMeを使用するBroadcomアダプタの各ホストバスアダプタ（HBA）ポートに関連付けられています。は、 `+hostnqn+`次の例のようにフォーマットされます。

....
nqn.2017-01.com.broadcom:ecd:nvmf:fc:100000109b1b9765
nqn.2017-01.com.broadcom:ecd:nvmf:fc:100000109b1b9766
....


=== NVMeデバイスでMPIOを有効にする

WindowsホストでNVMeの設定を完了するには、NVMeデバイスでMPIOを有効にする必要があります。

.手順
. をインストールします link:https://mysupport.netapp.com/site/products/all/details/hostutilities/downloads-tab/download/61343/7.1/downloads["Windows Host Utility Kit 7.1"] を使用して、FCとNVMeの両方に共通のドライバパラメータを設定します。
. MPIO のプロパティを開きます。
. [* マルチパスの検出 * ] タブで、 NVMe 用にリストされたデバイス ID を追加します。
+
MPIO は NVMe デバイスを認識し、 NVMe デバイスはディスク管理の下に表示されます。

. 「 * ディスクの管理」を開き、「 * ディスクのプロパティ * 」に移動します。
. [MPIO]*タブで、*[詳細]*を選択します。
. 次のMicrosoft DSM設定を行います。
+
** PathVerififiedPeriod ： * 10 *
** PathVerifyEnabled ： * Enable *
** RetryCount ： * 6 *
** 再試行間隔： * 1 *
** PDORemovedPeriod ： * 130*


. MPIO ポリシー * サブセット付きラウンドロビン * を選択します。
. レジストリ値を変更します。
+
[listing]
----
HKLM\SYSTEM\CurrentControlSet\Services\mpio\Parameters\PathRecoveryInterval DWORD -> 30

HKLM\SYSTEM\CurrentControlSet\Services\mpio \Parameters\ UseCustomPathRecoveryInterval  DWORD-> 1
----
. ホストをリブートします。




== NVMe/FC を検証

NVMeサブシステムが検出され、ONTAPネームスペースがNVMe-oFの設定に対応した正しいことを確認してください。

.手順
. [Port Type]が次のとおりであることを確認し `+FC+NVMe+`ます。
+
`listhba`

+
.例を示します
[%collapsible]
====
[listing, subs="+quotes"]
----
Port WWN       : 10:00:00:10:9b:1b:97:65
Node WWN       : 20:00:00:10:9b:1b:97:65
Fabric Name    : 10:00:c4:f5:7c:a5:32:e0
Flags          : 8000e300
Host Name      : INTEROP-57-159
Mfg            : Emulex Corporation
Serial No.     : FC71367217
Port Number    : 0
Mode           : Initiator
PCI Bus Number : 94
PCI Function   : 0
*Port Type*      : *FC+NVMe*
Model          : LPe32002-M2

Port WWN       : 10:00:00:10:9b:1b:97:66
Node WWN       : 20:00:00:10:9b:1b:97:66
Fabric Name    : 10:00:c4:f5:7c:a5:32:e0
Flags          : 8000e300
Host Name      : INTEROP-57-159
Mfg            : Emulex Corporation
Serial No.     : FC71367217
Port Number    : 1
Mode           : Initiator
PCI Bus Number : 94
PCI Function   : 1
Port Type      : FC+NVMe
Model          : LPe32002-M2
----
====
. NVMe/FCサブシステムが検出されたことを確認します。
+
** `+nvme-list+`
+
.例を示します
[%collapsible]
====
[listing]
----
NVMe Qualified Name     :  nqn.1992-08.com.netapp:sn.a3b74c32db2911eab229d039ea141105:subsystem.win_nvme_interop-57-159
Port WWN                :  20:09:d0:39:ea:14:11:04
Node WWN                :  20:05:d0:39:ea:14:11:04
Controller ID           :  0x0180
Model Number            :  NetApp ONTAP Controller
Serial Number           :  81CGZBPU5T/uAAAAAAAB
Firmware Version        :  FFFFFFFF
Total Capacity          :  Not Available
Unallocated Capacity    :  Not Available

NVMe Qualified Name     :  nqn.1992-08.com.netapp:sn.a3b74c32db2911eab229d039ea141105:subsystem.win_nvme_interop-57-159
Port WWN                :  20:06:d0:39:ea:14:11:04
Node WWN                :  20:05:d0:39:ea:14:11:04
Controller ID           :  0x0181
Model Number            :  NetApp ONTAP Controller
Serial Number           :  81CGZBPU5T/uAAAAAAAB
Firmware Version        :  FFFFFFFF
Total Capacity          :  Not Available
Unallocated Capacity    :  Not Available
Note: At present Namespace Management is not supported by NetApp Arrays.
----
====
** `nvme-list`
+
.例を示します
[%collapsible]
====
[listing]
----
NVMe Qualified Name     :  nqn.1992-08.com.netapp:sn.a3b74c32db2911eab229d039ea141105:subsystem.win_nvme_interop-57-159
Port WWN                :  20:07:d0:39:ea:14:11:04
Node WWN                :  20:05:d0:39:ea:14:11:04
Controller ID           :  0x0140
Model Number            :  NetApp ONTAP Controller
Serial Number           :  81CGZBPU5T/uAAAAAAAB
Firmware Version        :  FFFFFFFF
Total Capacity          :  Not Available
Unallocated Capacity    :  Not Available

NVMe Qualified Name     :  nqn.1992-08.com.netapp:sn.a3b74c32db2911eab229d039ea141105:subsystem.win_nvme_interop-57-159
Port WWN                :  20:08:d0:39:ea:14:11:04
Node WWN                :  20:05:d0:39:ea:14:11:04
Controller ID           :  0x0141
Model Number            :  NetApp ONTAP Controller
Serial Number           :  81CGZBPU5T/uAAAAAAAB
Firmware Version        :  FFFFFFFF
Total Capacity          :  Not Available
Unallocated Capacity    :  Not Available

Note: At present Namespace Management is not supported by NetApp Arrays.
----
====


. ネームスペースが作成されたことを確認します。
+
`+nvme-list-ns+`

+
.例を示します
[%collapsible]
====
[listing]
----
Active Namespaces (attached to controller 0x0141):

                                       SCSI           SCSI           SCSI
   NSID           DeviceName        Bus Number    Target Number     OS LUN
-----------  --------------------  ------------  ---------------   ---------
0x00000001   \\.\PHYSICALDRIVE9         0               1              0
0x00000002   \\.\PHYSICALDRIVE10        0               1              1
0x00000003   \\.\PHYSICALDRIVE11        0               1              2
0x00000004   \\.\PHYSICALDRIVE12        0               1              3
0x00000005   \\.\PHYSICALDRIVE13        0               1              4
0x00000006   \\.\PHYSICALDRIVE14        0               1              5
0x00000007   \\.\PHYSICALDRIVE15        0               1              6
0x00000008   \\.\PHYSICALDRIVE16        0               1              7

----
====

