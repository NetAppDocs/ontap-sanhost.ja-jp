---
sidebar: sidebar 
permalink: nvme_rhel_89.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: ONTAPを使用したRHEL 8.9用のNVMe-oFホストの設定方法 
---
= ONTAPを搭載したRHEL 8.9向けのNVMe-oFホストの設定
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:source-highlighter: highlighter.js


[role="lead"]
Red Hat Enterprise Linux（RHEL）8.9（Asymmetric Namespace Access（ANA）対応）では、NVMe over Fibre Channel（NVMe/FC）やその他のトランスポートを含むNVMe over Fabrics（NVMe-oF）がサポートされます。NVMe-oF環境では、ANAはiSCSI環境およびFC環境のALUAマルチパスに相当し、カーネル内NVMeマルチパスで実装されます。

ONTAPを使用したRHEL 8.9のNVMe-oFホスト構成では、次の機能がサポートされます。

* NVMe/FCに加えて、NVMe over TCP（NVMe/TCP）もサポートされます。標準のNVMe-CLIパッケージに含まれるNetAppプラグインには、NVMe/FCとNVMe/TCP両方のネームスペースのONTAPの詳細が表示されます。


サポートされる構成の詳細については、を参照してください link:https://mysupport.netapp.com/matrix/["NetApp Interoperability Matrix Tool で確認できます"^]。



== 既知の制限

* RHEL 8.9 NVMe-oFホストでは、カーネル内NVMeマルチパスはデフォルトで無効になっています。そのため、手動で有効にする必要があります。
* RHEL 8.9ホストでは、未解決の問題によりNVMe/TCPがテクノロジプレビュー機能になります。
* NVMe-oFプロトコルを使用したSANブートは現在サポートされていません。




== カーネル内マルチパスを有効にします

カーネル内マルチパスを有効にするには、次の手順を使用します。

.手順
. ホストサーバにRHEL 8.9をインストールします。
. インストールが完了したら、指定したRHEL 8.9カーネルが実行されていることを確認します。
+
[listing]
----
# uname -r
----
+
*出力例*

+
[listing]
----
4.18.0-513.5.1.el8_9.x86_64
----
. NVMe-CLIパッケージをインストールします。
+
[listing]
----
rpm -qa|grep nvme-cli
----
+
*出力例*

+
[listing]
----
nvme-cli-1.16-9.el8.x86_64
----
. カーネル内NVMeマルチパスを有効にします。
+
[listing]
----
# grubby --args=nvme_core.multipath=Y --update-kernel /boot/vmlinuz-4.18.0-513.5.1.el8_9.x86_64
----
. ホストで、でホストのNQN文字列を確認します `/etc/nvme/hostnqn`：
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
*出力例*

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:4c4c4544-0032-3410-8035-b8c04f4c5132
----
. を確認します `hostnqn` 文字列はに一致します `hostnqn` ONTAP アレイ上の対応するサブシステムの文字列。
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_fcnvme_141
----
+
*出力例*

+
[listing]
----
Vserver     Subsystem       Host NQN
----------- --------------- ----------------------------------------------------------
vs_nvme101 rhel_101_QLe2772    nqn.2014-08.org.nvmexpress: uuid:4c4c4544-0032-3410-8035-b8c04f4c5132
----
+

NOTE: ホストのNQN文字列が一致しない場合は、を使用できます `vserver modify` コマンドを実行して、対応するONTAP NVMeサブシステムのホストのNQN文字列をホストのNQN文字列と一致するように更新します `/etc/nvme/hostnqn` ホスト。

. ホストをリブートします。


[NOTE]
====
NVMeとSCSIの両方のトラフィックを同じホストで実行する場合NetAppは、ONTAPネームスペースにはカーネル内NVMeマルチパスを、ONTAP LUNにはdm-multipathをそれぞれ使用することを推奨します。これにより、ONTAPネームスペースがdm-multipathから除外され、dm-multipathがこれらのネームスペースデバイスを要求しないようにする必要があります。これを行うには、 `enable_foreign` に設定します `/etc/multipath.conf` ファイル：

[listing]
----
# cat /etc/multipath.conf
defaults {
  enable_foreign  NONE
}
----
====


== NVMe/FC を設定

NVMe/FCはBroadcom/EmulexアダプタまたはMarvell/Qlogicアダプタに設定できます。

[role="tabbed-block"]
====
.Broadcom / Emulex
--
.手順
. サポートされているアダプタモデルを使用していることを確認します。
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
*出力例：*

+
[listing]
----
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
*出力例：*

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. 推奨されるBroadcomを使用していることを確認します `lpfc` ファームウェアおよび受信トレイドライバ：
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.2.539.16, sli-4:2:c
14.2.539.16, sli-4:2:c
----
+
[listing]
----
# cat /sys/module/lpfc/version
0:14.0.0.21
----
+
サポートされているアダプタドライバとファームウェアのバージョンの最新リストについては、を参照してください link:https://mysupport.netapp.com/matrix/["NetApp Interoperability Matrix Tool で確認できます"^]。

. 確認します `lpfc_enable_fc4_type` がに設定されます `3`：
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. イニシエータポートが動作していること、およびターゲットLIFが表示されていることを確認します。
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x10000090fae0ec88
0x10000090fae0ec89
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing, subs="+quotes"]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x10000090fae0ec88 WWNN x20000090fae0ec88 DID x0a1300 *ONLINE*
NVME RPORT       WWPN x2049d039ea36a105 WWNN x2048d039ea36a105 DID x0a0c0a *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000024 Cmpl 0000000024 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 00000000000001aa Issue 00000000000001ab OutIO 0000000000000001
        abort 00000002 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000002 Err 00000003
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x10000090fae0ec89 WWNN x20000090fae0ec89 DID x0a1200 *ONLINE*
NVME RPORT       WWPN x204ad039ea36a105 WWNN x2048d039ea36a105 DID x0a080a *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000024 Cmpl 0000000024 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 00000000000001ac Issue 00000000000001ad OutIO 0000000000000001
        abort 00000002 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000002 Err 00000003



----


--
.NVMe / FC向けMarvell/QLogic FCアダプタ
--
.手順
. RHEL 8.9 GAカーネルに含まれているネイティブの受信トレイqla2xxxドライバには、ONTAPサポートに不可欠な最新のアップストリーム修正が含まれています。サポートされているアダプタドライバとファームウェアのバージョンが実行されていることを確認します。
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
----
+
*出力例*

+
[listing]
----
QLE2742 FW: v9.10.11 DVR: v10.02.08.200-k
QLE2742 FW: v9.10.11 DVR: v10.02.08.200-k
----
. 確認します `ql2xnvmeenable` が設定されます。これにより、MarvellアダプタをNVMe/FCイニシエータとして機能させることができます。
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 1MB I/Oを有効にする（オプション）

ONTAPは、Identify ControllerデータでMDT（MAX Data転送サイズ）を8と報告します。つまり、I/O要求の最大サイズは1MBまでです。ただし、Broadcom NVMe/FCホストに対する1MBの問題I/O要求には、を増やす必要があります `lpfc` の値 `lpfc_sg_seg_cnt` パラメータを256に設定します（デフォルト値の64から）。

.手順
. lpfc_sg_seg_cnt パラメータを 256 に設定します
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. 「 racut-f 」コマンドを実行し、ホストを再起動します。
. lpfc_sg_seg_cnt' が 256 であることを確認します
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----



NOTE: これはQlogic NVMe/FCホストには該当しません。



== NVMe/FC を設定

NVMe/TCPには自動接続機能はありません。そのため、パスがダウンしてデフォルトのタイムアウト（10分）内に復元されないと、NVMe/TCPは自動的に再接続できません。タイムアウトを回避するには、フェイルオーバーイベントの再試行期間を30分以上に設定する必要があります。

.手順
. イニシエータポートがサポートされているNVMe/TCP LIFの検出ログページのデータを取得できることを確認します。
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*出力例：*

+
[listing]
----
# nvme discover -t tcp -w 192.168.111.79 -a 192.168.111.14 -l 1800

Discovery Log Number of Records 8, Generation counter 18
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified.
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b: discovery
traddr:  192.168.211.15
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified.
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b: discovery
traddr:  192.168.111.15
sectype: none ..........


----
. NVMe/TCPイニシエータとターゲットLIFの他の組み合わせで、検出ログページのデータを正常に取得できることを確認します。
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*出力例：*

+
[listing]
----
# nvme	discovery	-t   tcp    -w	192.168.111.79   -a	192.168.111.14
# nvme	discovery	-t   tcp    -w	192.168.111.79   -a	192.168.111.15
# nvme	discovery	-t   tcp    -w	192.168.211.79   -a	192.168.211.14
# nvme	discovery	-t   tcp    -w	192.168.211.79   -a	192.168.211.15


----
. を実行します `nvme connect-all` ノード全体でサポートされているすべてのNVMe/TCPイニシエータ/ターゲットLIFを対象にコマンドを実行し、コントローラ損失のタイムアウト時間を30分または1、800秒以上に設定します。
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l 1800
----
+
*出力例：*

+
[listing]
----
# nvme	connect-all	-t	tcp	-w	192.168.111.79	-a	192.168.111.14	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.111.79	-a	192.168.111.15	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.211.79	-a	192.168.211.14	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.211.79	-a	192.168.211.15	-l	1800


----




== NVMe-oF を検証します

NVMe-oFの検証には、次の手順を使用できます。

.手順
. カーネル内NVMeマルチパスが有効になっていることを確認します。
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. NVMe-oFの適切な設定（など）を確認します。 `model` をに設定します `NetApp ONTAP Controller` 負荷分散 `iopolicy` をに設定します `round-robin`）それぞれのONTAPネームスペースがホストに正しく反映されるようになります。
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. ネームスペースが作成され、ホストで正しく検出されたことを確認します。
+
[listing]
----
# nvme list
----
+
*出力例：*

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme0n1 81Gx7NSiKSQqAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
. 各パスのコントローラの状態がliveであり、正しいANAステータスが設定されていることを確認します。
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme3n1
----
*出力例：*

[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.8e501f8ebafa11ec9b99d039ea359e4b:subsystem.rhel_163_Qle2742
+- nvme0 *fc* traddr=nn-0x204dd039ea36a105:pn-0x2050d039ea36a105 host_traddr=nn-0x20000024ff7f4994:pn-0x21000024ff7f4994 *live non-optimized*
+- nvme1 *fc* traddr=nn-0x204dd039ea36a105:pn-0x2050d039ea36a105 host_traddr=nn-0x20000024ff7f4994:pn-0x21000024ff7f4994 *live non-optimized*
+- nvme2 *fc* traddr=nn-0x204dd039ea36a105:pn-0x204fd039ea36a105 host_traddr=nn-0x20000024ff7f4995:pn-0x21000024ff7f4995 *live optimized*
+- nvme3 *fc* traddr=nn-0x204dd039ea36a105:pn-0x204ed039ea36a105 host_traddr=nn-0x20000024ff7f4994:pn-0x21000024ff7f4994 *live optimized*

----
--
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme0n1
----
*出力例：*

[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165\
+- nvme0 *tcp* traddr=192.168.111.15 trsvcid=4420 host_traddr=192.168.111.79 *live non-optimized*
+- nvme1 *tcp* traddr=192.168.111.14 trsvcid=4420 host_traddr=192.168.111.79 *live optimized*
+- nvme2 *tcp* traddr=192.168.211.15 trsvcid=4420 host_traddr=192.168.211.79 *live non-optimized*
+- nvme3 *tcp* traddr=192.168.211.14 trsvcid=4420 host_traddr=192.168.211.79 *live optimized*

----
--
====
. ネットアッププラグインで、ONTAP ネームスペースデバイスごとに正しい値が表示されていることを確認します。
+
[role="tabbed-block"]
====
.列（ Column ）
--
[listing]
----
# nvme netapp ontapdevices -o column
----
*出力例：*

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1 vs_tcp79           /vol/vol1/ns


NSID       UUID                                   Size
------------------------------------------------------------
1          aa197984-3f62-4a80-97de-e89436360cec	21.47GB
----
--
.JSON
--
[listing]
----
# nvme netapp ontapdevices -o json
----
*出力例*

[listing]
----
{
  "ONTAPdevices”: [
    {
      "Device”: "/dev/nvme0n1",
      "Vserver”: "vs_tcp79",
      "Namespace Path”: "/vol/vol1/ns",
      "NSID”: 1,
      "UUID”: "aa197984-3f62-4a80-97de-e89436360cec",
      "Size”: "21.47GB",
      "LBA_Data_Size”: 4096,
      "Namespace Size" : 5242880
    },
]

}


----
--
====




== 既知の問題

ONTAPリリースを使用したRHEL 8.9のNVMe-oFホスト設定には、次の既知の問題があります。

[cols="10,30,30,10"]
|===
| NetApp バグ ID | タイトル | 説明 | Bugzilla ID 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"^] | RHEL 8.9 NVMe-oFホストで重複する永続的検出コントローラが作成される | NVMe over Fabrics（NVMe-oF）ホストでは、「nvme discover -p」コマンドを使用して、Persistent Discovery Controller（PDC；永続的検出コントローラ）を作成できます。このコマンドを使用する場合は、イニシエータとターゲットの組み合わせごとにPDCを1つだけ作成する必要があります。  ただし、NVMe-oFホストでRed Hat Enterprise Linux（RHEL）8.9を実行している場合は、「nvme discover -p」を実行するたびに重複するPDCが作成されます。これにより、ホストとターゲットの両方で不要なリソースの使用が発生します。 | 2087000 
|===