---
sidebar: sidebar 
permalink: nvme_rhel_88.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: How to Configure NVMe-oF Host for RHEL 8.8 with<xmt-block0> ONTAP</xmt-block>を参照してください 
---
= ONTAPを使用したRHEL 8.8のNVMe-oFホスト構成
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:source-highlighter: highlighter.js
:toc-position: content


[role="lead"]
NVMe over Fibre Channel（NVMe/FC）やその他のトランスポートを含むNVMe over Fabrics（NVMe-oF）は、Red Hat Enterprise Linux（RHEL）8.8およびAsymmetric Namespace Access（ANA）でサポートされます。NVMe-oF環境では、ANAはiSCSI環境およびFC環境のALUAマルチパスに相当し、カーネル内NVMeマルチパスで実装されます。

ONTAPを使用したRHEL 8.8では、NVMe-oFホスト構成が次のようにサポートされます。

* NVMe/FCに加えて、NVMe over TCP（NVMe/TCP）もサポートされます。標準のNVMe-CLIパッケージに含まれるNetAppプラグインには、NVMe/FCとNVMe/TCP両方のネームスペースのONTAPの詳細が表示されます。


サポートされる構成の詳細については、を参照してください link:https://mysupport.netapp.com/matrix/["NetApp Interoperability Matrix Tool で確認できます"^]。



== 既知の制限

* RHEL 8.8 NVMe-oFホストでは、カーネル内NVMeマルチパスはデフォルトで無効になっています。そのため、手動で有効にする必要があります。
* RHEL 8.8ホストでは、未解決の問題によりNVMe/TCPがテクノロジプレビュー機能になります。




== カーネル内マルチパスを有効にします

次の手順を使用して、インカーネルマルチパスを有効にできます。

.手順
. ホストサーバにRHEL 8.8をインストールします。
. インストールが完了したら、指定したRHEL 8.8カーネルが実行されていることを確認します。
+
[listing]
----
# uname -r
----
+
*出力例*

+
[listing]
----
4.18.0-477.10.1.el8_8.x86_64
----
. NVMe-CLIパッケージをインストールします。
+
[listing]
----
rpm -qa|grep nvme-cli
----
+
*出力例*

+
[listing]
----
nvme-cli-1.16-7.el8.x86_64
----
. カーネル内NVMeマルチパスを有効にします。
+
[listing]
----
# grubby --args=nvme_core.multipath=Y --update-kernel /boot/vmlinuz-4.18.0-477.10.1.el8_8.x86_64
----
. ホストで、でホストのNQN文字列を確認します `/etc/nvme/hostnqn`：
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
*出力例*

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:f6517cae-3133-11e8-bbff-7ed30aef123f
----
. を確認します `hostnqn` 文字列はに一致します `hostnqn` ONTAP アレイ上の対応するサブシステムの文字列。
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_fcnvme_141
----
+
*出力例*

+
[listing]
----
Vserver     Subsystem       Host NQN
----------- --------------- ----------------------------------------------------------
vs_nvme161 rhel_161_LPe32002    nqn.2014-08.org.nvmexpress:uuid:f6517cae-3133-11e8-bbff-7ed30aef123f
----
+

NOTE: ホストのNQN文字列が一致しない場合は、を使用できます `vserver modify` コマンドを実行して、対応するONTAP NVMeサブシステムのホストのNQN文字列をホストのNQN文字列と一致するように更新します `/etc/nvme/hostnqn` ホスト。

. ホストをリブートします。


[NOTE]
====
NVMeとSCSIの両方のトラフィックを同じホストで実行する場合NetAppは、ONTAPネームスペースにはカーネル内NVMeマルチパスを、ONTAP LUNにはdm-multipathをそれぞれ使用することを推奨します。つまり、 dm-multipath がこれらのネームスペースデバイスを要求しないように、 ONTAP ネームスペースを dm-multipath から除外する必要があります。これを行うには、を追加します `enable_foreign` に設定します `/etc/multipath.conf` ファイル：

[listing]
----
# cat /etc/multipath.conf
defaults {
  enable_foreign  NONE
}
----
====


== NVMe/FC を設定

NVMe/FCはBroadcom/EmulexアダプタまたはMarvell/Qlogicアダプタに設定できます。

[role="tabbed-block"]
====
.Broadcom / Emulex
--
.手順
. サポートされているアダプタモデルを使用していることを確認します。
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
*出力例：*

+
[listing]
----
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
*出力例：*

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. 推奨されるBroadcomを使用していることを確認します `lpfc` ファームウェアおよび受信トレイドライバ：
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.0.639.18, sli-4:2:c
14.0.639.18, sli-4:2:c
----
+
[listing]
----
# cat /sys/module/lpfc/version
0:14.0.0.18
----
+
サポートされているアダプタドライバとファームウェアのバージョンの最新リストについては、を参照してください link:https://mysupport.netapp.com/matrix/["NetApp Interoperability Matrix Tool で確認できます"^]。

. 確認します `lpfc_enable_fc4_type` がに設定されます `3`：
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. イニシエータポートが動作していること、およびターゲットLIFが表示されていることを確認します。
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1c1204
0x100000109b1c1205
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x10000090fae0ec88 WWNN x20000090fae0ec88 DID x0a1300 ONLINE
NVME RPORT       WWPN x2049d039ea36a105 WWNN x2048d039ea36a105 DID x0a0c0a TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x204bd039ea36a105 WWNN x2048d039ea36a105 DID x0a100a TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000134 Cmpl 0000000134 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000825e567 Issue 000000000825d7ed OutIO fffffffffffff286
abort 0000027c noxri 00000000 nondlp 00000a02 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000782 Err 000130fa

NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x10000090fae0ec89 WWNN x20000090fae0ec89 DID x0a1200 ONLINE
NVME RPORT       WWPN x204ad039ea36a105 WWNN x2048d039ea36a105 DID x0a080a TARGET DISCSRVC ONLINE
NVME RPORT       WWPN x204cd039ea36a105 WWNN x2048d039ea36a105 DID x0a090a TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000134 Cmpl 0000000134 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000826ced5 Issue 000000000826c226 OutIO fffffffffffff351
        abort 0000029d noxri 00000000 nondlp 000008df qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000821 Err 00012fcd

----


--
.NVMe / FC向けMarvell/QLogic FCアダプタ
--
.手順
. RHEL 8.8 GAカーネルに含まれているネイティブの受信トレイqla2xxxドライバには、ONTAPサポートに不可欠な最新のアップストリーム修正が含まれています。サポートされているアダプタドライバとファームウェアのバージョンが実行されていることを確認します。
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
----
+
*出力例*

+
[listing]
----
QLE2772 FW:v9.10.11 DVR:v10.02.07.900-k-debug
QLE2772 FW:v9.10.11 DVR:v10.02.07.900-k-debug
----
. 確認します `ql2xnvmeenable` が設定されます。これにより、MarvellアダプタをNVMe/FCイニシエータとして機能させることができます。
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 1MB I/Oを有効にする（オプション）

ONTAPは、Identify ControllerデータでMDT（MAX Data転送サイズ）を8と報告します。つまり、I/O要求の最大サイズは1MBまでです。ただし、Broadcom NVMe/FCホストに対する1MBの問題I/O要求には、を増やす必要があります `lpfc` の値 `lpfc_sg_seg_cnt` パラメータを256に設定します（デフォルト値の64から）。

.手順
. lpfc_sg_seg_cnt パラメータを 256 に設定します
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. 「 racut-f 」コマンドを実行し、ホストを再起動します。
. lpfc_sg_seg_cnt' が 256 であることを確認します
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----



NOTE: これはQlogic NVMe/FCホストには該当しません。



== NVMe/FC を設定

NVMe/TCPには自動接続機能はありません。そのため、パスがダウンしてデフォルトのタイムアウト（10分）内に復元されないと、NVMe/TCPは自動的に再接続できません。タイムアウトを回避するには、フェイルオーバーイベントの再試行期間を30分以上に設定する必要があります。

.手順
. イニシエータポートがサポートされているNVMe/TCP LIFの検出ログページのデータを取得できることを確認します。
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*出力例：*

+
[listing]
----
# nvme discover -t tcp -w 192.168.111.79 -a 192.168.111.14

Discovery Log Number of Records 8, Generation counter 10
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.211.15
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.111.15
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:discovery
traddr:  192.168.211.14
sectype: none
..........
----
. NVMe/TCPイニシエータとターゲットLIFの他の組み合わせで、検出ログページのデータを正常に取得できることを確認します。
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*出力例：*

+
[listing]
----
# nvme	discovery	-t   tcp    -w	192.168.111.79   -a	192.168.111.14
# nvme	discovery	-t   tcp    -w	192.168.111.79   -a	192.168.111.15
# nvme	discovery	-t   tcp    -w	192.168.211.79   -a	192.168.211.14
# nvme	discovery	-t   tcp    -w	192.168.211.79   -a	192.168.211.15
----
. を実行します `nvme connect-all` ノード全体でサポートされているすべてのNVMe/TCPイニシエータ/ターゲットLIFを対象にコマンドを実行し、コントローラ損失のタイムアウト時間を30分または1、800秒以上に設定します。
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l 1800
----
+
*出力例：*

+
[listing]
----
# nvme	connect-all	-t	tcp	-w	192.168.111.79	-a	192.168.111.14	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.111.79	-a	192.168.111.15	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.211.79	-a	192.168.211.14	-l	1800
# nvme	connect-all	-t	tcp	-w	192.168.211.79	-a	192.168.211.15	-l	1800
----




== NVMe-oF を検証します

NVMe-oFの検証には、次の手順を使用できます。

.手順
. カーネル内NVMeマルチパスが有効になっていることを確認します。
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. NVMe-oFの適切な設定（など）を確認します。 `model` をに設定します `NetApp ONTAP Controller` 負荷分散 `iopolicy` をに設定します `round-robin`）それぞれのONTAPネームスペースがホストに正しく反映されるようになります。
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. ネームスペースが作成され、ホストで正しく検出されたことを確認します。
+
[listing]
----
# nvme list
----
+
*出力例：*

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme3n1 81Gx7NSiKSQeAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
. 各パスのコントローラの状態がliveであり、正しいANAステータスが設定されていることを確認します。
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme3n1
----
*出力例：*

[listing]
----
nvme-subsys3 - NQN=nqn.1992-08.com.netapp:sn.ab4fa6a5ba8b11ecbe3dd039ea359e4b:subsystem.rhel_161_Lpe32002
\
 +- nvme0 fc traddr=nn-0x2048d039ea36a105:pn-0x204cd039ea36a105 host_traddr=nn-0x20000090fae0ec89:pn-0x10000090fae0ec89 live non-optimized
 +- nvme1 fc traddr=nn-0x2048d039ea36a105:pn-0x204ad039ea36a105 host_traddr=nn-0x20000090fae0ec89:pn-0x10000090fae0ec89 live optimized
 +- nvme2 fc traddr=nn-0x2048d039ea36a105:pn-0x204bd039ea36a105 host_traddr=nn-0x20000090fae0ec88:pn-0x10000090fae0ec88 live non-optimized
 +- nvme4 fc traddr=nn-0x2048d039ea36a105:pn-0x2049d039ea36a105 host_traddr=nn-0x20000090fae0ec88:pn-0x10000090fae0ec88 live optimized
----
--
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme0n1
----
*出力例：*

[listing]
----
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.154a5833c78c11ecb069d039ea359e4b:subsystem.rhel_tcp_165
\
 +- nvme0 tcp traddr=192.168.111.15 trsvcid=4420 host_traddr=192.168.111.79 live non-optimized
 +- nvme1 tcp traddr=192.168.111.14 trsvcid=4420 host_traddr=192.168.111.79 live optimized
 +- nvme2 tcp traddr=192.168.211.15 trsvcid=4420 host_traddr=192.168.211.79 live non-optimized
----
--
====
. ネットアッププラグインで、ONTAP ネームスペースデバイスごとに正しい値が表示されていることを確認します。
+
[role="tabbed-block"]
====
.列（ Column ）
--
[listing]
----
# nvme netapp ontapdevices -o column
----
*出力例：*

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1 vs_tcp           /vol/vol1/ns1



NSID       UUID                                   Size
------------------------------------------------------------
1          338d73ce-b5a8-4847-9cc9-b127c75d8855	21.47GB
----
--
.JSON
--
[listing]
----
# nvme netapp ontapdevices -o json
----
*出力例*

[listing]
----
{
  "ONTAPdevices" : [
    {
      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_tcp79",
      "Namespace_Path" : "/vol/vol1/ns1",
      "NSID" : 1,
      "UUID" : "338d73ce-b5a8-4847-9cc9-b127c75d8855",
      "Size" : "21.47GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 5242880
    },
]

}

----
--
====




== 既知の問題

ONTAPリリースを搭載したRHEL 8.8のNVMe-oFホスト設定には、次の既知の問題があります。

[cols="10,30,30,10"]
|===
| NetApp バグ ID | タイトル | 説明 | Bugzilla ID 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"] | RHEL 8.8 NVMe-oFホストは、重複する永続的検出コントローラを作成します | NVMe over Fabrics（NVMe-oF）ホストでは、「nvme discover -p」コマンドを使用して、Persistent Discovery Controller（PDC；永続的検出コントローラ）を作成できます。このコマンドを使用する場合は、イニシエータとターゲットの組み合わせごとにPDCを1つだけ作成する必要があります。  ただし、NVMe-oFホストでRed Hat Enterprise Linux（RHEL）8.8を実行している場合は、「nvme discover -p」を実行するたびに重複するPDCが作成されます。これにより、ホストとターゲットの両方で不要なリソースの使用が発生します。 | 2087000 
|===


== トラブルシューティング

NVMe-oFの障害をトラブルシューティングする前に、実行している設定がIMTの仕様に準拠していることを確認してから、次の手順に進んでホスト側の問題をデバッグします。



=== 詳細ログを有効にします

構成に問題 が含まれている場合は、詳細なロギングを使用してトラブルシューティングに必要な情報を得ることができます。

.手順
Qlogicの詳細ロギングを設定する手順 （qla2xxx）は、lpfc詳細ロギングを設定する手順 とは異なります。

[role="tabbed-block"]
====
.LPFC
--
.手順
. を設定します `lpfc_log_verbose` NVMe/FCイベントをログに記録するためのドライバ設定は次のいずれかです。
+
[listing]
----
#define LOG_NVME 0x00100000 /* NVME general events. */
#define LOG_NVME_DISC 0x00200000 /* NVME Discovery/Connect events. */
#define LOG_NVME_ABTS 0x00400000 /* NVME ABTS events. */
#define LOG_NVME_IOERR 0x00800000 /* NVME IO Error events. */
----
. 値を設定したら、を実行します `dracut-f` コマンドを実行し、ホストをリブートします。
. 設定を確認します。
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_log_verbose=0xf00083

# cat /sys/module/lpfc/parameters/lpfc_log_verbose
15728771
----


--
.qla2xxx
--
NVMe/FCについては、同様の固有のqla2xxxロギングはありません `lpfc` ドライバ。したがって、次の手順を使用して一般的なqla2xxxログレベルを設定できます。

.手順
. 対応する「 m odprobe qla2xxx conf 」ファイルに「 ql2xextended_error_logging=0x1e400000 」の値を追加します。
. 「 d racut-f 」コマンドを実行して「 initramfs 」を再作成し、ホストを再起動します。
. リブート後、次のように詳細ログが適用されていることを確認します。
+
[listing]
----
# cat /etc/modprobe.d/qla2xxx.conf
options qla2xxx ql2xnvmeenable=1 ql2xextended_error_logging=0x1e400000
# cat /sys/module/qla2xxx/parameters/ql2xextended_error_logging
507510784
----


--
====


=== 一般的なnvme-CLIエラーとその回避策があります

によって表示されるエラーです `nvme-cli` 実行中 `nvme discover`、 `nvme connect`または `nvme connect-all` 処理とその対処方法を次の表に示します。

[cols="20, 20, 50"]
|===
| エラーは 'nvme-cli' によって表示されます | 原因と考えられます | 回避策 


| '/dev/nvme-Fabrics への書き込みに失敗しました : 引数が無効です | 構文が正しくありません | の正しい構文を使用していることを確認します `nvme discover`、 `nvme connect`および `nvme connect-all` コマンド 


| '/dev/nvme-Fabrics への書き込みに失敗しました : このようなファイルまたはディレクトリはありません | NVMeコマンドに誤った引数を指定した場合など、複数の問題が原因でこのエラーがトリガーされることがあります。  a| 
* コマンドに正しい引数（正しいWWNN文字列、WWPN文字列など）が渡されたことを確認します。
* 引数が正しいにもかかわらず、このエラーが引き続き表示される場合は、を確認してください `/sys/class/scsi_host/host*/nvme_info` コマンドの出力は正しいですが、NVMeイニシエータはと表示されます `Enabled`、およびNVMe/FCターゲットLIFがリモートポートのセクションに正しく表示されます。例
+
[listing]
----

# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
NVME LPORT lpfc0 WWPN x10000090fae0ec9d WWNN x20000090fae0ec9d DID x012000 ONLINE
NVME RPORT WWPN x200b00a098c80f09 WWNN x200a00a098c80f09 DID x010601 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000000000006 Cmpl 0000000000000006
FCP: Rd 0000000000000071 Wr 0000000000000005 IO 0000000000000031
Cmpl 00000000000000a6 Outstanding 0000000000000001
NVME Initiator Enabled
NVME LPORT lpfc1 WWPN x10000090fae0ec9e WWNN x20000090fae0ec9e DID x012400 ONLINE
NVME RPORT WWPN x200900a098c80f09 WWNN x200800a098c80f09 DID x010301 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000000000006 Cmpl 0000000000000006
FCP: Rd 0000000000000073 Wr 0000000000000005 IO 0000000000000031
Cmpl 00000000000000a8 Outstanding 0000000000000001
----
* ターゲットLIFがに表示されない場合は、で上記のように表示されます `nvme_info` コマンドの出力で、を確認します `/var/log/messages` および `dmesg` 疑わしいNVMe/FCエラーがないかどうかをコマンドで出力し、状況に応じて報告または修正




| ' 取得する検出ログエントリがありません  a| 
一般的には、が観察されます `/etc/nvme/hostnqn` 文字列がネットアップアレイの対応するサブシステムに追加されていないか、正しくありません `hostnqn` 文字列がそれぞれのサブシステムに追加されています。
 a| 
が正確であることを確認します `/etc/nvme/hostnqn` 文字列がネットアップアレイの対応するサブシステムに追加されます（を使用して確認してください） `vserver nvme subsystem host show` コマンド）。



| '/dev/nvme-Fabrics への書き込みに失敗しました：オペレーションはすでに進行中です  a| 
コントローラの関連付けまたは指定された操作がすでに作成されている場合、または作成中に発生した場合に表示されます。これは、上記にインストールされている自動接続スクリプトの一部として発生する可能性があります。
 a| 
なしを実行してみてください `nvme discover` しばらくしてからもう一度コマンドを実行してください。の場合 `nvme connect` および `connect-all`を実行します `nvme list` コマンドを使用して、ネームスペースデバイスが作成済みで、ホストに表示されていることを確認します。

|===


=== テクニカルサポートへの連絡のタイミング

問題が解決しない場合は、次のファイルとコマンドの出力を収集し、テクニカルサポートに問い合わせてトリアージを依頼してください。

[listing]
----
cat /sys/class/scsi_host/host*/nvme_info
/var/log/messages
dmesg
nvme discover output as in:
nvme discover --transport=fc --traddr=nn-0x200a00a098c80f09:pn-0x200b00a098c80f09 --host-traddr=nn-0x20000090fae0ec9d:pn-0x10000090fae0ec9d
nvme list
nvme list-subsys /dev/nvmeXnY
----